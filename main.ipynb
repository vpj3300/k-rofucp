{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import optuna\n",
    "import joblib\n",
    "import optuna.visualization as vis\n",
    "import plotly.io as pio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_study(study, study_file_name = 'studies/generic_study.pkl', report_file_name = 'studies/generic_study.csv'):\n",
    "    # Save the study\n",
    "    joblib.dump(study, study_file_name)\n",
    "\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_df.sort_values(by='value', ascending=True).head(3)\n",
    "    study_df.to_csv(report_file_name, index=False)\n",
    "\n",
    "    return study_df\n",
    "\n",
    "def load_study(study_file_name=None, report_file_name=None):\n",
    "    study = None\n",
    "    study_df = None\n",
    "    if study_file_name != None:\n",
    "        study = joblib.load(study_file_name)\n",
    "    if report_file_name != None:\n",
    "        study_df = pd.read_csv(report_file_name)\n",
    "    \n",
    "    return study, study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df  = pd.read_csv(\"/kaggle/input/playground-series-s4e9/test.csv\")\n",
    "train_df = pd.read_csv(\"/kaggle/input/playground-series-s4e9/train.csv\")\n",
    "\n",
    "X_train = train_df.drop(['id','price'], axis=1)\n",
    "y_train = train_df['price']\n",
    "\n",
    "id_column = test_df['id']\n",
    "X_test = test_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([X_train, X_test], keys=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = combined_data.select_dtypes(include='object').columns\n",
    "\n",
    "for col in categorical:\n",
    "    if combined_data[col].isna().sum() > 0:\n",
    "        mode = combined_data[col].mode()[0]\n",
    "        combined_data[col].fillna(mode, inplace=True)\n",
    "\n",
    "encoders = {}\n",
    "for var in categorical:\n",
    "    le = LabelEncoder()\n",
    "    combined_data[var] = le.fit_transform(combined_data[var])\n",
    "    encoders[var] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_data.xs('train')\n",
    "X_test = combined_data.xs('test')\n",
    "\n",
    "x1, x2, y1, y2 = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',  # Gradient Boosting Decision Tree\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 120),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 700),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 0.8),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 0.8),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 120),\n",
    "        'device': 'gpu', \n",
    "        'gpu_use_dp': False,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "    model.fit(x1, y1, eval_set=[(x2, y2)], callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "    \n",
    "    y_pred = model.predict(x2)\n",
    "    rmse = mean_squared_error(y2, y_pred, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "lgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "lgb_study.optimize(lgb_objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\", lgb_study.best_params)\n",
    "print(\"Best RMSE:\", lgb_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1500),\n",
    "        'depth': trial.suggest_int('depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.5),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-5, 100),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 1),\n",
    "        'random_seed': 42,\n",
    "        'loss_function': 'RMSE',\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "\n",
    "    cat_model = CatBoostRegressor(**params, early_stopping_rounds=20, verbose=0)\n",
    "    \n",
    "    cat_model.fit(Pool(x1, y1), eval_set=Pool(x2, y2))\n",
    "    \n",
    "    y_pred = cat_model.predict(x2)\n",
    "    \n",
    "    rmse = mean_squared_error(y2, y_pred, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "cat_study = optuna.create_study(direction='minimize')\n",
    "cat_study.optimize(cat_objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\", cat_study.best_params)\n",
    "print(\"Best RMSE:\", cat_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-5, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-5, 10.0),\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(**params, early_stopping_rounds=50, verbosity=0)\n",
    "\n",
    "    xgb_model.fit(x1, y1, eval_set=[(x2, y2)], verbose=False)\n",
    "\n",
    "    y_pred = xgb_model.predict(x2)\n",
    "\n",
    "    rmse = mean_squared_error(y2, y_pred, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "xgb_study.optimize(xgb_objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\", xgb_study.best_params)\n",
    "print(\"Best RMSE:\", xgb_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the best models for each study\n",
    "top = 5\n",
    "\n",
    "catboost_top = [cat_study.trials[i].params for i in cat_study.trials_dataframe().sort_values(by='value',ascending=True)['number'][:top]]\n",
    "lgb_top      = [lgb_study.trials[i].params for i in lgb_study.trials_dataframe().sort_values(by='value',ascending=True)['number'][:top]]\n",
    "xgb_top      = [xgb_study.trials[i].params for i in xgb_study.trials_dataframe().sort_values(by='value',ascending=True)['number'][:top]]\n",
    "catboost_models = [CatBoostRegressor(**params) for params in catboost_top]\n",
    "lgb_models      = [lgb.LGBMRegressor(**params) for params in lgb_top]\n",
    "xgb_models      = [xgb.XGBRegressor(**params) for params in xgb_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('catboost_' + str(i), model) for i, model in enumerate(catboost_models)] + \n",
    "               [('lgb_' + str(i), model) for i, model in enumerate(lgb_models)] +\n",
    "               [('xgb_' + str(i), model) for i, model in enumerate(xgb_models)],\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train, y_train)\n",
    "y_pred = stacked_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': id_column, 'price': y_pred})\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
